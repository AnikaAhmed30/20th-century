import pandas as pd 
import numpy as np
import spacy
from spacy import displacy
import networkx as nx
import os
import matplotlib.pyplot as plt
import scipy
import re

!python -m spacy download en_core_web_sm

# Load spacy English module

NER = spacy.load("en_core_web_sm")


#Open file
with open("Key_Events_20th_Century.txt", "r", errors="ignore") as file:
    data = file.read().replace('\n', ' ')
#Display a preview to inspect
print(data[:5000])


#Observations:
#The text includes Wikipedia navigation and special characters
#Country Names inconsistencies exist
#Some lines have extra newlines or tabs from wiki formatting.
#Clean by removing wiki artifacts, extra whitespace, and non-content sections


# Clean the text: Remove wiki artifacts, references, and extra whitespace
# Remove [edit]
cleaned_text = re.sub(r'\[edit\]', '', data) 
# Remove references like [123]
cleaned_text = re.sub(r'\[\d+\]', '', cleaned_text)  
# Remove ^
cleaned_text = re.sub(r'\^', '', cleaned_text)  
# Remove headers/footers
cleaned_text = re.sub(r'Jump to content|Main menu|move to sidebar|hide|Navigation|Main pageContentsCurrent eventsRandom articleAbout WikipediaContact us|Contribute|HelpLearn to editCommunity portalRecent changesUpload fileSpecial pages|Search|Appearance|Donate|Create account|Log in|Personal tools|Pages for logged out editors learn more|ContributionsTalk|Toggle the table of contents|languages|Edit links|ArticleTalk|English|ReadEditView history|Tools|Actions|General|What links hereRelated changesUpload filePermanent linkPage informationCite this pageGet shortened URLDownload QR code|Print/export|Download as PDFPrintable version|In other projects|Wikimedia CommonsWikidata item|From Wikipedia, the free encyclopedia|Retrieved from.*', '', cleaned_text, flags=re.DOTALL)
# Normalize whitespace
cleaned_text = re.sub(r'\s+', ' ', cleaned_text)  

cleaned_text = cleaned_text.strip()


# Save cleaned text as .txt
with open("Cleaned_Key_Events_20th_Century.txt", "w", encoding="utf-8") as file:
    file.write(cleaned_text)

# Preview cleaned text
print(cleaned_text[:1000])


# Process the cleaned text with spaCy NER
doc = NER(cleaned_text)


# Create a list of sentences and entities
df_sentences = []
for sent in doc.sents:
    entity_list = [ent.text for ent in sent.ents]
    df_sentences.append({"sentence": sent.text, "entities": entity_list})

df_sentences = pd.DataFrame(df_sentences)


print(df_sentences.head())


# Load countries list
countries_df = pd.read_csv("countries_list_20th_century_1.5.csv")
countries_df['country_name'] = countries_df['country_name'].str.strip().str.replace(r'^"|"$', '', regex=True)


# Define variation mapping for consistency
country_variations = {
    'US': 'United States',
    'USA': 'United States',
    'America': 'United States',
    'Britain': 'United Kingdom',
    'UK': 'United Kingdom',
    'Soviet Union': 'Russia',
    'USSR': 'Russia',
    'Great Britain': 'United Kingdom',
    'Congo Free State': 'Congo, Democratic Republic of the',
    'Persia': 'Iran',
    'North Korea': 'Korea, North',
    'South Korea': 'Korea, South'}


# Define function to filter entities
def filter_entity(ent_list, countries_df):
    return [country_variations.get(ent, ent) for ent in ent_list if country_variations.get(ent, ent) in countries_df['country_name'].tolist()]


# Apply filter
df_sentences['country_entities'] = df_sentences['entities'].apply(lambda x: filter_entity(x, countries_df))


# Filter out rows with no countries
df_sentences_filtered = df_sentences[df_sentences['country_entities'].map(len) > 0]

print(df_sentences_filtered.head())


# Create relationships
relationships = []

for i in range(df_sentences_filtered.index[-1]):
    end_i = min(i + 5, df_sentences_filtered.index[-1])
    char_list = sum((df_sentences_filtered.loc[i:end_i].country_entities), [])
    char_unique = [char_list[i] for i in range(len(char_list)) if (i == 0) or char_list[i] != char_list[i-1]]
    
    if len(char_unique) > 1:
        for idx, a in enumerate(char_unique[:-1]):
            b = char_unique[idx + 1]
            relationships.append({"source": a, "target": b})

# Create DataFrame
relationships_df = pd.DataFrame(relationships)

# Preview
print(relationships_df.head(10))


#Sort each row alphabetically
relationships_df = pd.DataFrame(
    np.sort(relationships_df.values, axis=1),
    columns=relationships_df.columns)


relationship_counts = relationships_df.value_counts().reset_index(name="count")

print(relationship_counts.head())


# Save to CSV
relationship_counts.to_csv("country_relationships.csv", index=False)



